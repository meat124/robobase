# BRS Policy Training Guide

BigYM SaucepanToHob íƒœìŠ¤í¬ë¥¼ ìœ„í•œ BRS (Bi-Manual Robot System) Policy í•™ìŠµ ê°€ì´ë“œ

## ëª©ì°¨
1. [ê°œìš”](#1-ê°œìš”)
2. [ë°ì´í„°ì…‹ êµ¬ì¡°](#2-ë°ì´í„°ì…‹-êµ¬ì¡°)
3. [ë°ì´í„° ë¡œë”© íŒŒì´í”„ë¼ì¸](#3-ë°ì´í„°-ë¡œë”©-íŒŒì´í”„ë¼ì¸)
4. [ëª¨ë¸ ì•„í‚¤í…ì²˜](#4-ëª¨ë¸-ì•„í‚¤í…ì²˜)
5. [í•™ìŠµ ê³¼ì •](#5-í•™ìŠµ-ê³¼ì •)
6. [ì‹¤í–‰ ë°©ë²•](#6-ì‹¤í–‰-ë°©ë²•)
7. [ì„¤ì • íŒŒë¼ë¯¸í„°](#7-ì„¤ì •-íŒŒë¼ë¯¸í„°)
8. [Rollout í‰ê°€](#8-rollout-í‰ê°€)
9. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#9-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## 1. ê°œìš”

### 1.1 BRS Policyë€?
BRS PolicyëŠ” Point Cloudì™€ Proprioceptionì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë¡œë´‡ì˜ í–‰ë™ì„ ì˜ˆì¸¡í•˜ëŠ” **Diffusion ê¸°ë°˜ ëª¨ë°© í•™ìŠµ** ëª¨ë¸ì…ë‹ˆë‹¤.

```
ì…ë ¥: Point Cloud (4096, 3) + Proprioception (16D)
     â†“
ëª¨ë¸: Transformer + Conditional Diffusion
     â†“
ì¶œë ¥: Action Chunks (H, 16) - Hê°œì˜ ë¯¸ë˜ í–‰ë™ ì˜ˆì¸¡
```

### 1.2 ì£¼ìš” íŠ¹ì§•
- **Temporal Windowing**: ìµœê·¼ Tê°œ í”„ë ˆì„ì˜ ê´€ì¸¡ì„ ì‚¬ìš© (ê¸°ë³¸ T=2)
- **Action Chunking**: Hê°œì˜ ë¯¸ë˜ í–‰ë™ì„ í•œë²ˆì— ì˜ˆì¸¡ (ê¸°ë³¸ H=8)
- **Autoregressive Action**: í–‰ë™ì„ mobile_base â†’ torso â†’ arms ìˆœì„œë¡œ ë¶„í•´
- **Conditional Diffusion**: DDPM ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±°ë¡œ í–‰ë™ ìƒì„±

---

## 2. ë°ì´í„°ì…‹ êµ¬ì¡°

### 2.1 íŒŒì¼ êµ¬ì¡°
```
data/demonstrations/saucepan_to_hob/
â”œâ”€â”€ demos.hdf5              # ì£¼ ë°ì´í„° íŒŒì¼ (13GB)
â”œâ”€â”€ pcd/                    # Point Cloud íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ demo_000_pcd.npy    # (T_demo, 4096, 3) per demo
â”‚   â”œâ”€â”€ demo_001_pcd.npy
â”‚   â””â”€â”€ ...
â”œâ”€â”€ action_stats.json       # Action ì •ê·œí™” í†µê³„
â”œâ”€â”€ prop_stats.json         # Proprioception ì •ê·œí™” í†µê³„
â””â”€â”€ pcd_stats.json          # PCD XYZ ì •ê·œí™” í†µê³„
```

### 2.2 HDF5 êµ¬ì¡°
```
demos.hdf5
â”œâ”€â”€ demo_0/
â”‚   â”œâ”€â”€ actions                    # (T, 16) - 16D í–‰ë™
â”‚   â”œâ”€â”€ proprioception             # (T, 60) - ì „ì²´ ê´€ì ˆ ìƒíƒœ
â”‚   â”œâ”€â”€ proprioception_floating_base  # (T, 4) - [x, y, z, rz]
â”‚   â”œâ”€â”€ proprioception_grippers    # (T, 2) - [left, right]
â”‚   â”œâ”€â”€ rgb_head                   # (T, H, W, 3) - í—¤ë“œ ì¹´ë©”ë¼ RGB
â”‚   â””â”€â”€ depth_head                 # (T, H, W) - í—¤ë“œ ì¹´ë©”ë¼ ê¹Šì´
â”œâ”€â”€ demo_1/
â””â”€â”€ ... (ì´ 31ê°œ ë°ëª¨, ~27k timesteps)
```

### 2.3 Action êµ¬ì¡° (16D)
BRS PolicyëŠ” BigYMì˜ 16D í–‰ë™ì„ ë‹¤ìŒê³¼ ê°™ì´ ë¶„í•´í•©ë‹ˆë‹¤:

| êµ¬ì„±ìš”ì†Œ | ì°¨ì› | ì¸ë±ìŠ¤ | ì„¤ëª… |
|---------|------|--------|------|
| mobile_base | 3D | [0:3] | dx, dy, drz (ì´ë™) |
| torso | 1D | [3:4] | dz (ë†’ì´) |
| arms | 12D | [4:16] | left_arm(5) + left_grip(1) + right_arm(5) + right_grip(1) |

#### ğŸ”„ BRS â†’ BigYM ì•¡ì…˜ ë¦¬ë§¤í•‘
BRSì™€ BigYMì€ ì•¡ì…˜ ìˆœì„œê°€ ë‹¤ë¦…ë‹ˆë‹¤:

```
BRS 16D:    [X, Y, RZ, Z, left_arm(5), left_grip, right_arm(5), right_grip]
             0  1   2  3     4-8           9          10-14         15

BigYM 16D:  [X, Y, Z, RZ, left_arm(5), right_arm(5), left_grip, right_grip]
             0  1  2   3     4-8          9-13           14         15
```

**ì¤‘ìš”**: BigYM í™˜ê²½ì—ì„œ rollout í‰ê°€ ì‹œ, `_brs_to_bigym_action()` í•¨ìˆ˜ì—ì„œ ì´ ë³€í™˜ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤:
```python
def _brs_to_bigym_action(brs_action):
    # BRS: [X, Y, RZ, Z, left_arm(5), left_grip, right_arm(5), right_grip]
    # BigYM: [X, Y, Z, RZ, left_arm(5), right_arm(5), left_grip, right_grip]
    bigym_action = np.zeros(16)
    bigym_action[0] = brs_action[0]   # X
    bigym_action[1] = brs_action[1]   # Y
    bigym_action[2] = brs_action[3]   # Z (BRSì˜ index 3)
    bigym_action[3] = brs_action[2]   # RZ (BRSì˜ index 2)
    bigym_action[4:9] = brs_action[4:9]    # left_arm(5)
    bigym_action[9:14] = brs_action[10:15] # right_arm(5)
    bigym_action[14] = brs_action[9]       # left_gripper
    bigym_action[15] = brs_action[15]      # right_gripper
    return bigym_action
```

### 2.4 Proprioception êµ¬ì¡° (16D)
| êµ¬ì„±ìš”ì†Œ | ì°¨ì› | ì†ŒìŠ¤ | ì„¤ëª… |
|---------|------|------|------|
| mobile_base_vel | 3D | diff(floating_base)/dt | ì†ë„ [vx, vy, vrz] |
| torso | 1D | floating_base[2] | ë†’ì´ z |
| left_arm | 5D | qpos[0,1,2,3,12] | ì™¼íŒ” ê´€ì ˆ |
| left_gripper | 1D | grippers[0] | ì™¼ì† ê·¸ë¦¬í¼ |
| right_arm | 5D | qpos[13,14,15,16,25] | ì˜¤ë¥¸íŒ” ê´€ì ˆ |
| right_gripper | 1D | grippers[1] | ì˜¤ë¥¸ì† ê·¸ë¦¬í¼ |

### 2.5 ì •ê·œí™” í†µê³„ íŒŒì¼

#### action_stats.json
```json
{
  "mobile_base": {"min": [...], "max": [...], "mean": [...], "std": [...]},
  "torso": {"min": ..., "max": ..., "mean": ..., "std": ...},
  "arms": {"min": [...], "max": [...], "mean": [...], "std": [...]},
  "full": {"min": [16D], "max": [16D], "mean": [16D], "std": [16D]}
}
```

#### prop_stats.json
```json
{
  "mobile_base_vel": {"min": [3D], "max": [3D], ...},
  "torso": {"min": scalar, "max": scalar, ...},
  "left_arm": {"min": [5D], "max": [5D], ...},
  "left_gripper": {"min": scalar, "max": scalar, ...},
  "right_arm": {"min": [5D], "max": [5D], ...},
  "right_gripper": {"min": scalar, "max": scalar, ...},
  "full": {"min": [16D], "max": [16D], ...}
}
```

#### pcd_stats.json
```json
{
  "xyz": {
    "min": [-0.828, -0.828, 0.051],
    "max": [0.821, 0.601, 2.0],
    "mean": [-0.063, -0.018, 0.305],
    "std": [0.278, 0.233, 0.781]
  }
}
```

---

## 3. ë°ì´í„° ë¡œë”© íŒŒì´í”„ë¼ì¸

### 3.1 ì „ì²´ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PCDDataModule                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Train/Val    â”‚â”€â”€â”€â–¶â”‚ PCDBRSDatasetâ”‚â”€â”€â”€â–¶â”‚  DataLoader  â”‚       â”‚
â”‚  â”‚ Demo Split   â”‚    â”‚              â”‚    â”‚ (8 workers)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PCDBRSDataset.__getitem__                    â”‚
â”‚                                                                  â”‚
â”‚  1. Sample Index â†’ (demo_id, frame_idx)                         â”‚
â”‚  2. Load T frames of:                                            â”‚
â”‚     - PCD: pcd/demo_XXX_pcd.npy[frame_idx:frame_idx+T]          â”‚
â”‚     - Proprioception: HDF5ì—ì„œ ì¶”ì¶œ ë° ë³€í™˜                       â”‚
â”‚     - Actions: HDF5ì—ì„œ Hê°œ ë¯¸ë˜ í–‰ë™ ë¡œë“œ                        â”‚
â”‚  3. Normalize (if enabled):                                      â”‚
â”‚     - PCD: (xyz - min) / (max - min) * 2 - 1 â†’ [-1, 1]          â”‚
â”‚     - Prop/Action: (x - min) / (max - min) * 2 - 1 â†’ [-1, 1]    â”‚
â”‚  4. Return batch dict                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 ìƒ˜í”Œ ì¸ë±ìŠ¤ êµ¬ì¡°

ê° ìƒ˜í”Œì€ íŠ¹ì • ë°ëª¨ì˜ íŠ¹ì • ì‹œì ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤:
```python
# _build_sample_index()ì—ì„œ ìƒì„±
samples = [
    (demo_id="demo_0", frame_idx=0),
    (demo_id="demo_0", frame_idx=1),
    ...
    (demo_id="demo_1", frame_idx=0),
    ...
]
# ìœ íš¨ ë²”ìœ„: T-1 â‰¤ frame_idx â‰¤ len(demo) - H
```

### 3.3 __getitem__ ìƒì„¸

```python
def __getitem__(self, idx):
    demo_id, frame_idx = self.samples[idx]
    
    # 1. Point Cloud ë¡œë“œ (T frames)
    pcd_file = f"pcd/{demo_id}_pcd.npy"
    pcd = np.load(pcd_file)[frame_idx-T+1:frame_idx+1]  # (T, N, 3)
    
    # 2. Proprioception ì¶”ì¶œ (T frames)
    with h5py.File(hdf5_path, 'r') as f:
        demo = f[demo_id]
        # Mobile base velocity (ì°¨ë¶„ ê³„ì‚°)
        fb = demo['proprioception_floating_base'][frame_idx-T:frame_idx+1]
        mobile_base_vel = np.diff(fb[:, [0,1,3]], axis=0) / dt
        
        # Torso (z position)
        torso = fb[1:, 2:3]
        
        # Arms (QPOSì—ì„œ íŠ¹ì • ì¸ë±ìŠ¤ ì¶”ì¶œ)
        qpos = demo['proprioception'][frame_idx-T+1:frame_idx+1]
        left_arm = qpos[:, [0,1,2,3,12]]
        right_arm = qpos[:, [13,14,15,16,25]]
        
        # Grippers
        grippers = demo['proprioception_grippers'][frame_idx-T+1:frame_idx+1]
    
    # 3. Action Chunks (H frames)
    actions = demo['actions'][frame_idx:frame_idx+H]  # (H, 16)
    
    # 4. ì •ê·œí™”
    if self.normalize:
        pcd = normalize_to_minus1_plus1(pcd, self.pcd_xyz_min, self.pcd_xyz_max)
        prop = normalize_to_minus1_plus1(prop, self.prop_min, self.prop_max)
        actions = normalize_to_minus1_plus1(actions, self.action_min, self.action_max)
    
    return {
        'pointcloud': {'xyz': pcd, 'rgb': rgb},
        'qpos': {'torso': torso, 'left_arm': left_arm, ...},
        'odom': {'mobile_base': mobile_base_vel},
        'action_chunks': {'mobile_base': actions[:,:3], 'torso': actions[:,3:4], 'arms': actions[:,4:]},
        'pad_mask': pad_mask
    }
```

### 3.4 Batch Collation

```python
def pcd_brs_collate_fn(batch):
    """
    ì—¬ëŸ¬ ìƒ˜í”Œì„ ë°°ì¹˜ë¡œ ë¬¶ìŒ
    
    Input: List of dicts
    Output: Nested dict with batched tensors
    
    Shape conventions:
    - pcd: (B, num_cams, T, N, 3)
    - qpos: (B, num_cams, T, dim)
    - actions: (B, num_cams, T, H, dim)
    """
```

### 3.5 ë°ì´í„° ë¡œë”© ìµœì í™”

| ìµœì í™” | ì„¤ëª… |
|--------|------|
| Per-worker HDF5 handles | ê° workerê°€ ë…ë¦½ì ì¸ HDF5 íŒŒì¼ í•¸ë“¤ ìœ ì§€ |
| Prefetch factor=4 | 4ë°°ì¹˜ë¥¼ ë¯¸ë¦¬ ë¡œë“œ |
| Persistent workers | Worker ì¬ìƒì„± ì˜¤ë²„í—¤ë“œ ì œê±° |
| Pin memory | GPU ì „ì†¡ ê°€ì† |
| Chunk cache | HDF5 ì²­í¬ ìºì‹± |

**ì„±ëŠ¥**: ~690 samples/sec (8 workers)

---

## 4. ëª¨ë¸ ì•„í‚¤í…ì²˜

### 4.1 ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BRS Policy                                â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PointNet   â”‚   â”‚ Prop MLP   â”‚   â”‚    Transformer         â”‚   â”‚
â”‚  â”‚ Encoder    â”‚   â”‚ Encoder    â”‚   â”‚    (2 layers)          â”‚   â”‚
â”‚  â”‚            â”‚   â”‚            â”‚   â”‚                        â”‚   â”‚
â”‚  â”‚ PCD(N,3)   â”‚   â”‚ Prop(16)   â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚    â†“       â”‚   â”‚    â†“       â”‚   â”‚  â”‚ Self-Attention   â”‚  â”‚   â”‚
â”‚  â”‚ (256,)     â”‚   â”‚ (256,)     â”‚   â”‚  â”‚ + Cross-Attn     â”‚  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ to observations  â”‚  â”‚   â”‚
â”‚        â”‚                â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚           â”‚            â”‚   â”‚
â”‚                 â”‚                  â”‚           â–¼            â”‚   â”‚
â”‚                 â–¼                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚  â”‚ Action Readout   â”‚  â”‚   â”‚
â”‚         â”‚ Observation  â”‚           â”‚  â”‚ Token            â”‚  â”‚   â”‚
â”‚         â”‚ Tokens       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚         â”‚ (T, 256)     â”‚           â”‚           â”‚            â”‚   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚           â–¼            â”‚   â”‚
â”‚                                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                                    â”‚  â”‚ Diffusion Head   â”‚  â”‚   â”‚
â”‚                                    â”‚  â”‚ (Conditional     â”‚  â”‚   â”‚
â”‚                                    â”‚  â”‚  U-Net 1D)       â”‚  â”‚   â”‚
â”‚                                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                 â”‚                â”‚
â”‚                                                 â–¼                â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                    â”‚  Action Chunks (H, 16) â”‚   â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 ì¸ì½”ë”

#### PointNet Encoder
```python
# ì…ë ¥: (B, T, N, 3) - Tê°œ í”„ë ˆì„, Nê°œ í¬ì¸íŠ¸, XYZ
# ì¶œë ¥: (B, T, 256) - í”„ë ˆì„ë³„ íŠ¹ì§•

class PointNetEncoder:
    def __init__(self):
        self.mlp = MLP([3, 64, 128, 256])  # Per-point features
        self.max_pool = GlobalMaxPool()     # Permutation invariant
    
    def forward(self, x):
        x = self.mlp(x)           # (B, T, N, 256)
        x = self.max_pool(x)      # (B, T, 256)
        return x
```

#### Proprioception MLP Encoder
```python
# ì…ë ¥: (B, T, 16) - 16D proprioception
# ì¶œë ¥: (B, T, 256) - í”„ë ˆì„ë³„ íŠ¹ì§•

class PropMLP:
    def __init__(self):
        self.layers = MLP([16, 256, 256])  # 2-layer MLP
```

### 4.3 Transformer

```python
class ObservationTransformer:
    def __init__(self):
        self.n_embd = 256
        self.n_layer = 2
        self.n_head = 8
        self.dropout = 0.1
    
    def forward(self, obs_tokens, action_readout_token):
        # obs_tokens: (B, T, 256) - PCD + Prop ê²°í•©
        # action_readout_token: (B, 1, 256) - learnable or fixed
        
        # Concat and apply transformer
        tokens = concat([obs_tokens, action_readout_token])
        output = self.transformer(tokens)
        
        # Extract action condition
        action_cond = output[:, -1, :]  # (B, 256)
        return action_cond
```

### 4.4 Diffusion Head

```python
class ConditionalUNet1D:
    """
    DDPM ê¸°ë°˜ ì¡°ê±´ë¶€ í–‰ë™ ìƒì„±
    
    Training:
        1. ê¹¨ë—í•œ actionì— ë…¸ì´ì¦ˆ ì¶”ê°€
        2. ë…¸ì´ì¦ˆ ë ˆë²¨ + observation conditionìœ¼ë¡œ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
        3. ì˜ˆì¸¡ ë…¸ì´ì¦ˆì™€ ì‹¤ì œ ë…¸ì´ì¦ˆì˜ MSE Loss
    
    Inference:
        1. ìˆœìˆ˜ ë…¸ì´ì¦ˆì—ì„œ ì‹œì‘
        2. ë°˜ë³µì ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±° (16 steps)
        3. ìµœì¢… action chunks ì¶œë ¥
    """
    
    def __init__(self):
        self.down_dims = [64, 128]
        self.kernel_size = 5
        self.n_groups = 8
        self.num_train_timesteps = 100
        self.num_inference_steps = 16
```

---

## 5. í•™ìŠµ ê³¼ì •

### 5.1 ì „ì²´ í•™ìŠµ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Training Loop                                â”‚
â”‚                                                                  â”‚
â”‚  for epoch in range(max_epochs):                                â”‚
â”‚      for batch in train_dataloader:                             â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚          â”‚ 1. Forward Pass                                   â”‚   â”‚
â”‚          â”‚    - Encode PCD â†’ pcd_features                   â”‚   â”‚
â”‚          â”‚    - Encode Prop â†’ prop_features                 â”‚   â”‚
â”‚          â”‚    - Transformer â†’ action_condition              â”‚   â”‚
â”‚          â”‚    - Sample noise timestep t                     â”‚   â”‚
â”‚          â”‚    - Add noise to GT actions                     â”‚   â”‚
â”‚          â”‚    - Predict noise with UNet                     â”‚   â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚          â”‚ 2. Compute Loss                                   â”‚   â”‚
â”‚          â”‚    loss = MSE(predicted_noise, actual_noise)     â”‚   â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚          â”‚ 3. Backward Pass                                  â”‚   â”‚
â”‚          â”‚    - loss.backward()                             â”‚   â”‚
â”‚          â”‚    - gradient_clip(1.0)                          â”‚   â”‚
â”‚          â”‚    - optimizer.step()                            â”‚   â”‚
â”‚          â”‚    - lr_scheduler.step()                         â”‚   â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚      # Validation                                               â”‚
â”‚      if epoch % eval_interval == 0:                             â”‚
â”‚          val_loss = validate(val_dataloader)                    â”‚
â”‚          log_to_wandb(train_loss, val_loss, lr)                â”‚
â”‚                                                                  â”‚
â”‚      # Rollout Evaluation (optional)                            â”‚
â”‚      if epoch % rollout_interval == 0:                          â”‚
â”‚          success_rate = evaluate_in_env()                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Forward Pass ìƒì„¸

```python
def training_step(self, batch):
    # 1. ì…ë ¥ ì¶”ì¶œ
    pcd = batch['pointcloud']['xyz']           # (B, num_cams, T, N, 3)
    prop = self._flatten_prop(batch['qpos'])   # (B, T, 16)
    gt_actions = self._flatten_actions(batch['action_chunks'])  # (B, H, 16)
    
    # 2. ì¸ì½”ë”©
    pcd_features = self.pointnet(pcd)          # (B, T, 256)
    prop_features = self.prop_mlp(prop)        # (B, T, 256)
    obs_features = pcd_features + prop_features  # (B, T, 256)
    
    # 3. Transformer
    action_cond = self.transformer(obs_features)  # (B, 256)
    
    # 4. Diffusion Loss
    # Sample random timestep
    t = torch.randint(0, self.num_train_timesteps, (B,))
    
    # Add noise to actions
    noise = torch.randn_like(gt_actions)
    noisy_actions = self.scheduler.add_noise(gt_actions, noise, t)
    
    # Predict noise
    pred_noise = self.unet(noisy_actions, t, action_cond)
    
    # MSE Loss
    loss = F.mse_loss(pred_noise, noise)
    
    return loss
```

### 5.3 Learning Rate Schedule

```
LR
 â”‚
 â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚    â”‚ Warmup (1000 steps)
0.0007â”œâ”€â”€â”€â”€â”˜
 â”‚    
 â”‚                    Cosine Decay
 â”‚                         â•²
 â”‚                          â•²
 â”‚                           â•²
0.000005â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Steps
      0    1000                              300000
```

### 5.4 Inference (Action Generation)

```python
def predict_action(self, observation):
    # 1. ì¸ì½”ë”©
    pcd_features = self.pointnet(observation['pcd'])
    prop_features = self.prop_mlp(observation['prop'])
    action_cond = self.transformer(pcd_features + prop_features)
    
    # 2. Diffusion Sampling (16 steps)
    actions = torch.randn(B, H, 16)  # Start from noise
    
    for t in reversed(range(16)):
        pred_noise = self.unet(actions, t, action_cond)
        actions = self.scheduler.step(pred_noise, t, actions)
    
    # 3. Denormalize
    actions = denormalize(actions, self.action_min, self.action_max)
    
    return actions  # (B, H, 16)
```

---

## 6. ì‹¤í–‰ ë°©ë²•

### 6.1 í•™ìŠµ ì‹¤í–‰

```bash
cd /home/hyunjin/bigym_ws/robobase

# ê¸°ë³¸ ì‹¤í–‰
bash train_brs.sh

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
python -m robobase.method.brs_lightning \
    --config robobase/cfgs/brs_config.yaml \
    --use-pcd \
    --bs 64 \
    --vbs 64 \
    --dataloader-num-workers 8 \
    --wandb-name brs_experiment_1
```

### 6.2 ì£¼ìš” CLI ì˜µì…˜

| ì˜µì…˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `--config` | Config YAML ê²½ë¡œ | brs_config.yaml |
| `--use-pcd` | PCD ë°ì´í„°ì…‹ ì‚¬ìš© | False |
| `--hdf5-path` | HDF5 íŒŒì¼ ê²½ë¡œ | config ê°’ |
| `--pcd-root` | PCD ë””ë ‰í† ë¦¬ ê²½ë¡œ | config ê°’ |
| `--bs` | ë°°ì¹˜ í¬ê¸° | 256 |
| `--vbs` | ê²€ì¦ ë°°ì¹˜ í¬ê¸° | 256 |
| `--lr` | í•™ìŠµë¥  | 0.0007 |
| `--seed` | ëœë¤ ì‹œë“œ | 42 |
| `--no-wandb` | WandB ë¹„í™œì„±í™” | False |
| `--wandb-name` | WandB ì‹¤í–‰ ì´ë¦„ | config ê°’ |
| `--dataloader-num-workers` | ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜ | 16 |

### 6.3 WandB ë¡œê¹…

í•™ìŠµ ì¤‘ ë‹¤ìŒ ë©”íŠ¸ë¦­ì´ WandBì— ë¡œê¹…ë©ë‹ˆë‹¤:
- `train/loss`: í•™ìŠµ ì†ì‹¤
- `val/loss`: ê²€ì¦ ì†ì‹¤
- `lr`: í˜„ì¬ í•™ìŠµë¥ 
- `epoch`: í˜„ì¬ ì—í­
- GPU/CPU ì‚¬ìš©ë¥ 

#### Run Directory êµ¬ì¡°
í•™ìŠµ ê²°ê³¼ë¬¼ì€ `runs/{wandb_name}/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤:
```
runs/
â””â”€â”€ brs_experiment_1/           # --wandb-name ê°’ê³¼ ë™ì¼
    â”œâ”€â”€ checkpoints/
    â”‚   â”œâ”€â”€ last.ckpt
    â”‚   â””â”€â”€ best-epoch=XX-val_loss=X.XX.ckpt
    â”œâ”€â”€ tb/                     # TensorBoard ë¡œê·¸
    â”œâ”€â”€ logs/                   # CSV ë¡œê·¸
    â””â”€â”€ wandb/                  # WandB ë¡œì»¬ ìºì‹œ
```

**ì°¸ê³ **: `--wandb-name` ì˜µì…˜ì„ ì§€ì •í•˜ë©´ ë¡œì»¬ run directoryì™€ WandB run ì´ë¦„ì´ ë™ì¼í•˜ê²Œ ì„¤ì •ë©ë‹ˆë‹¤.

---

## 7. ì„¤ì • íŒŒë¼ë¯¸í„°

### 7.1 brs_config.yaml ì£¼ìš” ì„¤ì •

```yaml
# ====== Training ======
seed: 42
gpus: 1
lr: 0.0007
bs: 256                    # batch_size
vbs: 256                   # val_batch_size
val_split_ratio: 0.1
max_epochs: 10000
gradient_clip_val: 1.0

# ====== LR Schedule ======
use_cosine_lr: true
lr_warmup_steps: 1000
lr_cosine_steps: 300000
lr_cosine_min: 0.000005

# ====== Model ======
action_dim: 16
prop_dim: 16
num_latest_obs: 2          # Temporal window T
action_prediction_horizon: 8  # Action horizon H

# ====== PointNet ======
pointnet_hidden_dim: 256
pcd_downsample_points: 2048

# ====== Transformer ======
xf_n_embd: 256
xf_n_layer: 2
xf_n_head: 8
xf_dropout_rate: 0.1

# ====== Diffusion ======
noise_scheduler:
  num_train_timesteps: 100
  beta_schedule: "squaredcos_cap_v2"
num_denoise_steps_per_inference: 16

# ====== Data ======
hdf5_path: ".../demos.hdf5"
pcd_root: ".../pcd"
action_stats_path: ".../action_stats.json"
prop_stats_path: ".../prop_stats.json"
pcd_stats_path: ".../pcd_stats.json"
normalize: true
normalize_pcd: true
```

### 7.2 í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¶Œì¥ê°’

| íŒŒë¼ë¯¸í„° | ê¶Œì¥ê°’ | ì„¤ëª… |
|---------|--------|------|
| bs | 64-256 | GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ |
| lr | 5e-4 ~ 1e-3 | í° ë°°ì¹˜ì—ì„  ë†’ê²Œ |
| num_latest_obs | 2 | ê´€ì¸¡ ìœˆë„ìš° |
| action_prediction_horizon | 8 | ì˜ˆì¸¡ í˜¸ë¼ì´ì¦Œ |
| pcd_downsample_points | 2048-4096 | ê³„ì‚°ëŸ‰ê³¼ ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„ |
| xf_n_layer | 2-4 | ëª¨ë¸ ìš©ëŸ‰ |
| num_denoise_steps | 16-50 | ì†ë„ì™€ í’ˆì§ˆ íŠ¸ë ˆì´ë“œì˜¤í”„ |

---

## 8. Rollout í‰ê°€

### 8.1 ê°œìš”
í•™ìŠµëœ ì •ì±…ì„ BigYM í™˜ê²½ì—ì„œ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

### 8.2 BigYM í™˜ê²½ ì„¤ì •

#### PelvisDof ì„¤ì • (ì¤‘ìš”!)
BigYMì—ì„œ torso Z ì¶• ì œì–´ë¥¼ ìœ„í•´ `PelvisDof.Z`ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

```python
from bigym.action_modes import PelvisDof

env = BiGymEnv(
    action_mode=JointPositionActionMode(
        floating_base=True,
        floating_dofs=[PelvisDof.X, PelvisDof.Y, PelvisDof.Z, PelvisDof.RZ],  # 4D
        absolute=False,
    ),
    # ...
)
```

**ì£¼ì˜**: ê¸°ë³¸ BigYM ì„¤ì •ì€ `floating_dofs=[X, Y, RZ]` (3D)ì…ë‹ˆë‹¤. BRS ì •ì±…ì˜ 16D ì•¡ì…˜ê³¼ í˜¸í™˜ë˜ë ¤ë©´ Zì¶•ì„ í¬í•¨í•œ 4Dê°€ í•„ìš”í•©ë‹ˆë‹¤.

| floating_dofs | ì´ ì•¡ì…˜ ì°¨ì› | í˜¸í™˜ì„± |
|---------------|-------------|--------|
| [X, Y, RZ] (ê¸°ë³¸) | 15D | âŒ ë¶ˆì¼ì¹˜ |
| [X, Y, Z, RZ] | 16D | âœ… BRS í˜¸í™˜ |

### 8.3 Rollout Callback ì„¤ì •

`robobase/rollout_callback.py`ì—ì„œ í™˜ê²½ ìƒì„± ì‹œ ì˜¬ë°”ë¥¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```python
def _create_env(self):
    env = BiGymEnv(
        task=SaucepanToHob,
        action_mode=JointPositionActionMode(
            floating_base=True,
            floating_dofs=[PelvisDof.X, PelvisDof.Y, PelvisDof.Z, PelvisDof.RZ],
            absolute=False,
        ),
        observation_config=ObservationConfig(
            cameras=[
                CameraConfig(name="head", resolution=(84, 84)),
            ],
            proprioception=True,
        ),
        render_mode="rgb_array",
    )
    return env
```

### 8.4 í‰ê°€ ë©”íŠ¸ë¦­
- `rollout/success_rate`: ì„±ê³µë¥  (0~1)
- `rollout/avg_return`: í‰ê·  ë¦¬í„´
- `rollout/avg_episode_length`: í‰ê·  ì—í”¼ì†Œë“œ ê¸¸ì´

---

## 9. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 9.1 ì•¡ì…˜ ì°¨ì› ë¶ˆì¼ì¹˜ ì˜¤ë¥˜
```
Error: Action dimension mismatch: expected 15, got 16
```

**ì›ì¸**: BigYM í™˜ê²½ì´ ê¸°ë³¸ `floating_dofs=[X, Y, RZ]`ë¡œ ì„¤ì •ë˜ì–´ 15D ì•¡ì…˜ë§Œ ë°›ìŒ

**í•´ê²°**: `floating_dofs`ì— `PelvisDof.Z` ì¶”ê°€:
```python
floating_dofs=[PelvisDof.X, PelvisDof.Y, PelvisDof.Z, PelvisDof.RZ]
```

### 9.2 ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
--bs 32 --vbs 32

# í¬ì¸íŠ¸ ìˆ˜ ì¤„ì´ê¸° (configì—ì„œ)
pcd_downsample_points: 1024
```

### 9.3 ë°ì´í„° ë¡œë”© ëŠë¦¼
```bash
# ì›Œì»¤ ìˆ˜ ëŠ˜ë¦¬ê¸°
--dataloader-num-workers 8

# Prefetch ëŠ˜ë¦¬ê¸° (configì—ì„œ)
prefetch_factor: 4
persistent_workers: true
```

### 9.4 í•™ìŠµ ë¶ˆì•ˆì •
```yaml
# Configì—ì„œ gradient clipping ì¡°ì ˆ
gradient_clip_val: 0.5

# í•™ìŠµë¥  ë‚®ì¶”ê¸°
lr: 0.0003
```

---

## ì°¸ê³  ìë£Œ

- [BRS-Algo Repository](https://github.com/brs-algo)
- [BigYM Documentation](https://github.com/chernyadev/bigym)
- [Diffusion Policy Paper](https://arxiv.org/abs/2303.04137)
- [ACT Paper](https://arxiv.org/abs/2304.13705)
