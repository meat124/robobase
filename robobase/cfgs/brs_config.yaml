# BRS Policy Configuration
# Uses BigYM 16D action format (native)

# ====== Main cfg ======
seed: 42
gpus: 1
lr: 0.0007
use_cosine_lr: true
lr_warmup_steps: 1000
lr_cosine_steps: 300000
lr_cosine_min: 0.000005
lr_layer_decay: 1.0
wd: 0.1
bs: 256
vbs: 256
val_split_ratio: 0.1
dataloader_num_workers: 16
eval_interval: 10

# ------ Rollout Evaluation ------
rollout_eval: true
rollout_eval_interval: 500
num_eval_episodes: 1
log_eval_video: true
max_episode_steps: 500
env_name: "FlipCup"

gradient_clip_val: 1.0
max_epochs: 10000
precision: "bf16-mixed"
use_torch_compile: true
torch_compile_mode: "reduce-overhead"

# ------ logging ------
use_wandb: true
wandb_project: "brs_policy"
wandb_name: "brs_policy_run"
log_every_n_steps: 10

# ------ Action Structure (BigYM Native with BRS Autoregressive) ------
# BigYM 16D raw: [floating_base(4) + left_arm(5) + right_arm(5) + grippers(2)]
#   floating_base: [dx, dy, dz, drz]
#
# BRS 3-part autoregressive structure (reordered):
#   - mobile_base: 3D (dx, dy, drz) - DELTA position
#   - torso: 1D (dz) - DELTA position  
#   - arms: 12D (left_arm 5 + right_arm 5 + grippers 2) - ABSOLUTE position
action_dim: 16
action_keys: ["mobile_base", "torso", "arms"]
action_key_dims:
  mobile_base: 3
  torso: 1
  arms: 12

# ====== Architecture ======
num_latest_obs: 2
action_prediction_horizon: 8

# ------ Proprioception (BigYM Native with BRS Structure) ------
# 16D: mobile_base_pos(3) + torso_z(1) + arms(12)
#   mobile_base_pos: [x, y, rz] from floating_base
#   torso_z: z from floating_base
#   arms: left_arm(5) + left_gripper(1) + right_arm(5) + right_gripper(1)
prop_dim: 16
prop_keys: ["odom/mobile_base_pos", "qpos/torso", "qpos/left_arm", "qpos/left_gripper", "qpos/right_arm", "qpos/right_gripper"]
use_modality_type_tokens: false
prop_mlp_hidden_depth: 2
prop_mlp_hidden_dim: 256
pointnet_n_coordinates: 3
pointnet_n_color: 3
pointnet_hidden_depth: 2
pointnet_hidden_dim: 256
pcd_downsample_points: 4096

# ====== Transformer ======
xf_n_embd: 256
xf_n_layer: 2
xf_n_head: 8
xf_dropout_rate: 0.1
xf_use_geglu: true

# ====== Action Decoding ======
learnable_action_readout_token: false
diffusion_step_embed_dim: 128
unet_down_dims: [64, 128]
unet_kernel_size: 5
unet_n_groups: 8
unet_cond_predict_scale: true

# ====== Diffusion ======
noise_scheduler:
  num_train_timesteps: 100
  beta_start: 0.0001
  beta_end: 0.02
  beta_schedule: "squaredcos_cap_v2"
  clip_sample: true
  set_alpha_to_one: true
  steps_offset: 0
  prediction_type: "epsilon"

noise_scheduler_step_kwargs: null
num_denoise_steps_per_inference: 16

# ====== Module ======
loss_on_latest_obs_only: false

# ====== Dataset Settings ======
hdf5_path: null  # Set via CLI
pcd_root: null   # Set via CLI
cameras: ["head"]
max_points_per_camera: 4096
demo_ids: null
use_hdf5_pcd: false
subsample_points: true
normalize_pcd: true

# ====== Normalization ======
normalize: true
action_stats_path: null  # Auto-set from hdf5_path
prop_stats_path: null
pcd_stats_path: null
